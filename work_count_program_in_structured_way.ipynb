{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "235a8689-d3e9-48e6-9fb1-9c385d670627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CleanUp Activity is started\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Do you want to truncate the delta table (y/n): y"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta table truncated successfully\nCleanUp Activity is finished\n\nList of files available in the input folder:\n  1 : file_list.txt\n['file_list.txt']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "select the file number from the above list:  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying files for processing\nCopying files is done\n\n"
     ]
    }
   ],
   "source": [
    "%run ./workcount_cleanup_activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2553215-0e15-4d82-b6f9-8a2e6f8d3eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data processing started..Done\n\nQuality data processing started..Done\n\nAggregation on data started..Done\n\nInserting data into delta tables...Done\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode, lower, trim\n",
    "\n",
    "class WordCount:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_dir = cls.base_dir\n",
    "        self.df = spark.read.option('lineSep','.').text(f'{self.base_dir}/working')\n",
    "    \n",
    "    def raw_data(self):\n",
    "        return self.df.withColumn('new_col', explode(split(self.df.value,'')))\n",
    "    \n",
    "    def quality_data(self, Rawdf):\n",
    "        df1 = Rawdf.select(lower(trim(Rawdf.new_col)).alias('new_col'))\\\n",
    "            .where(Rawdf['new_col'].isNotNull())\\\n",
    "            .where(Rawdf.new_col.rlike(\"[a-zA-Z]\"))\n",
    "        return df1\n",
    "    \n",
    "    def aggregation_col(self, Quadf):\n",
    "        df = Quadf.groupBy(Quadf.new_col).count()\n",
    "        return df\n",
    "    \n",
    "    def inserting_into_table(self, Aggdf):\n",
    "        df = Aggdf.write.format('delta')\\\n",
    "                        .mode('overwrite')\\\n",
    "                        .saveAsTable('wordcount_table')\n",
    "        \n",
    "    \n",
    "    def launcher(self):\n",
    "        print('Raw data processing started..', end='')\n",
    "        Rawdf = self.raw_data()\n",
    "        #print(Rawdf.display())\n",
    "        print('Done\\n')\n",
    "        print('Quality data processing started..', end='')\n",
    "        Quadf = self.quality_data(Rawdf)\n",
    "        print('Done\\n')\n",
    "        print('Aggregation on data started..', end='')\n",
    "        Aggdf = self.aggregation_col(Quadf)\n",
    "        print('Done\\n')\n",
    "        print('Inserting data into delta tables...', end='')\n",
    "        self.inserting_into_table(Aggdf)\n",
    "        print('Done')\n",
    "\n",
    "cls = WordCount()\n",
    "cls.launcher()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "work_count_program_in_structured_way",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
